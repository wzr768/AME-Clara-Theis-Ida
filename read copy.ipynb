{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Technology\n",
    "\n",
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import Project_1 as lm\n",
    "from scipy.stats import chi2\n",
    "from numpy import linalg as la\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('firms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['lcap','lemp','ldsa']].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='lemp', y='ldsa', data=dat); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data to numpy format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.ldsa.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = dat.firmid.unique().size\n",
    "T = dat.year.unique().size\n",
    "assert dat.shape[0] == N*T, f'Error: data is not a balanced panel'\n",
    "print(f'Data has N={N} and T={T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from `pandas` to `numpy` arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dat.ldsa.values.reshape((N*T,1))\n",
    "\n",
    "ones = np.ones((N*T,1))\n",
    "l = dat.lemp.values.reshape((N*T,1))\n",
    "k = dat.lcap.values.reshape((N*T,1))\n",
    "x = np.hstack([l, k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for odd years\n",
    "dat_odd_years = dat[dat['year'] % 2 != 0].copy()\n",
    "\n",
    "# Update T\n",
    "T = dat_odd_years.year.unique().size\n",
    "assert dat_odd_years.shape[0] == N*T, f'Error: data is not a balanced panel'\n",
    "print(f'Data has N={N} and T={T}')\n",
    "\n",
    "#naming the dependent and independent variables\n",
    "label_y = 'Log deflated sales'\n",
    "label_x = [\n",
    "    'log of employment',\n",
    "    'log of adjusted capital stock'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model using OLS\n",
    "ols_result = lm.estimate(y,x, transform='', T=T, robust_se='True')\n",
    "\n",
    "# Print table\n",
    "lm.print_table((label_y, label_x), ols_result, title=\"Pooled OLS\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "Q_T = np.eye(T) - np.tile(1/T, (T, T))\n",
    "y_dot = lm.perm(Q_T, y)\n",
    "x_dot = lm.perm(Q_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_dot, label_x_dot = lm.remove_zero_columns(x_dot, label_x)\n",
    "\n",
    "# Estimate \n",
    "fe_result = lm.estimate(y_dot, x_dot, transform='fe', T=T, robust_se='True')\n",
    "lm.print_table((label_y, label_x_dot), fe_result, title=\"Fixed Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "D_T = (np.eye(T) - np.eye(T, k=-1))[1:]\n",
    "\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_diff, label_x_diff = lm.remove_zero_columns(x_diff, label_x)\n",
    "\n",
    "# Estimate \n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', T=T-1, robust_se='True')\n",
    "lm.print_table((label_y, label_x_diff), fd_result, title=\"First Difference\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "P_T = np.ones((1,T)) * 1/T\n",
    "\n",
    "y_mean = lm.perm(P_T, y)\n",
    "x_mean = lm.perm(P_T, x)\n",
    "\n",
    "# Estimate \n",
    "be_result = lm.estimate(y_mean, x_mean, transform='be', T=T, robust_se='True')\n",
    "lm.print_table((label_y, label_x), be_result, title=\"Between Estimator\", floatfmt='.4f')\n",
    "\n",
    "# Calculate lambda (note lambda is a reserved keyword in Python, so we use _lambda instead)\n",
    "sigma2_u = fe_result['sigma2']\n",
    "sigma2_w = be_result['sigma2']\n",
    "sigma2_c = sigma2_w - 1/T * sigma2_u\n",
    "_lambda = 1 - np.sqrt(sigma2_u / (sigma2_u + T*sigma2_c))\n",
    "\n",
    "# Print lambda \n",
    "print(f'Lambda is approximately equal to {_lambda.item():.4f}.')\n",
    "\n",
    "# Transform the data\n",
    "C_T = - np.eye(T, T) + _lambda * P_T\n",
    "y_re = lm.perm(C_T, y)\n",
    "x_re = lm.perm(C_T, x)\n",
    "\n",
    "# Estimate \n",
    "re_result = lm.estimate(y_re, x_re, transform='re', T=T, robust_se='True')\n",
    "lm.print_table((label_y, label_x), re_result, title=\"Random Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for constant returns to scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define null hypothesis: R * b_hat = 1 (sum of first two coefficients equals 1)\n",
    "R = np.array([[1, 1]])\n",
    "r = np.array([[1]])\n",
    "\n",
    "# Extract b_hat and covariance matrix\n",
    "b_hat = fe_result['b_hat']  # Estimated coefficients\n",
    "cov = fe_result['cov']      # Covariance matrix of coefficients\n",
    "\n",
    "# Perform Wald test\n",
    "w_stat, crit_val, p_value = lm.wald_test(b_hat, cov, R, r)\n",
    "\n",
    "print(f'The test statistic is {w_stat.item():.2f}.')\n",
    "print(f'The critical value at a 5% significance level is {crit_val:.2f}.')\n",
    "print(f'The p-value is {p_value:.8f}.')\n",
    "\n",
    "if w_stat > crit_val:\n",
    "    print(f\"Reject null hypothesis: We reject CRS for the FE-estimation - P-value of: {p_value:.4f}.\")\n",
    "else:\n",
    "    print(f\"Fail to reject null hypothesis: We cannot reject CRS for the FE-estimation. P-value of: {p_value:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract b_hat and covariance matrix\n",
    "b_hat = fd_result['b_hat']  # Estimated coefficients\n",
    "cov = fd_result['cov']      # Covariance matrix of coefficients\n",
    "\n",
    "# Perform Wald test\n",
    "w_stat, crit_val, p_value = lm.wald_test(b_hat, cov, R, r)\n",
    "\n",
    "print(f'The test statistic is {w_stat.item():.2f}.')\n",
    "print(f'The critical value at a 5% significance level is {crit_val:.2f}.')\n",
    "print(f'The p-value is {p_value:.8f}.')\n",
    "\n",
    "if w_stat > crit_val:\n",
    "    print(f\"Reject null hypothesis: We reject CRS for the FD-estimation - P-value of: {p_value:.4f}.\")\n",
    "else:\n",
    "    print(f\"Fail to reject null hypothesis: We cannot reject CRS for the FD-estimation. P-value of: {p_value:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hausman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack\n",
    "b_fe = fe_result['b_hat']\n",
    "b_re = re_result['b_hat']\n",
    "cov_fe = fe_result['cov']\n",
    "cov_re = re_result['cov']\n",
    "\n",
    "# Calculate the test statistic\n",
    "b_diff = b_fe - b_re\n",
    "cov_diff = cov_fe - cov_re\n",
    "H = b_diff.T @ la.inv(cov_diff) @ b_diff\n",
    "\n",
    "# Find critical value and p-value at 5% significance level of chi^2 with M degrees of freedom\n",
    "M = len(b_diff)\n",
    "crit_val = chi2.ppf(0.95, M)\n",
    "p_val = 1 - chi2.cdf(H.item(), M)\n",
    "\n",
    "# Print the results\n",
    "print(f'The test statistic is {H.item():.2f}.')\n",
    "print(f'The critical value at a 5% significance level is {crit_val:.2f}.')\n",
    "print(f'The p-value is {p_val:.8f}.')\n",
    "\n",
    "if H > crit_val:\n",
    "    print(f\"Reject null hypothesis: Prefer FE estimator over RE estimator, since the test statistic is greater than the critical value: {H.item():.2f} > {crit_val:.2f}.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Prefer RE estimator over FE estimator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for serial correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests assumption FD.3, where the errors $e_{it} = \\Delta u_{it}$ should be serially uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to calculate the serial correlation\n",
    "def serial_corr(y, x, T):\n",
    "    # Calculate the residuals\n",
    "    b_hat = lm.est_ols(y, x)\n",
    "    e = y - x@b_hat\n",
    "    \n",
    "    # Create a lag transformation matrix\n",
    "    L_T = np.eye(T, k=-1)\n",
    "    L_T = L_T[1:]\n",
    "\n",
    "    # Lag residuals\n",
    "    e_l = lm.perm(L_T, e)\n",
    "\n",
    "    # Create a transformation matrix that removes the first observation of each individual\n",
    "    I_T = np.eye(T, k=0)\n",
    "    I_T = I_T[1:]\n",
    "    \n",
    "    # Remove first observation of each individual\n",
    "    e = lm.perm(I_T, e)\n",
    "    \n",
    "    # Calculate the serial correlation\n",
    "    return lm.estimate(e, e_l,T=T-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate serial correlation\n",
    "corr_result = serial_corr(y_diff, x_diff, T-1)\n",
    "\n",
    "# Print results\n",
    "label_ye = 'OLS residual, e\\u1d62\\u209c'\n",
    "label_e = ['e\\u1d62\\u209c\\u208B\\u2081']\n",
    "lm.print_table(\n",
    "    (label_ye, label_e), corr_result, \n",
    "    title='Serial Correlation', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for strict exogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing FE.1 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead employment\n",
    "F_T = np.eye(T, k=1)[:-1]\n",
    "empl_lead = lm.perm(F_T, x[:, 0].reshape(-1, 1))\n",
    "\n",
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)[:-1]\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)\n",
    "\n",
    "# Add empl_lead to x_exo\n",
    "x_exo = np.hstack((x_exo, empl_lead))\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = np.eye(T-1) - np.tile(1/(T-1), ((T-1), (T-1))) #Demeaning matrix\n",
    "yw_exo = lm.perm(Q_T, y_exo)\n",
    "xw_exo = lm.perm(Q_T, x_exo)\n",
    "\n",
    "# Estimate model\n",
    "exo_test = lm.estimate(yw_exo, xw_exo, T=T-1, transform='fe', robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo = label_x + ['Employment lead']\n",
    "lm.print_table((label_y, label_exo), exo_test, title='Exogeneity FE test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead capital\n",
    "F_T = np.eye(T, k=1)[:-1]\n",
    "cap_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))\n",
    "\n",
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)[:-1]\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)\n",
    "\n",
    "# Add empl_lead to x_exo\n",
    "x_exo = np.hstack((x_exo, cap_lead))\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = np.eye(T-1) - np.tile(1/(T-1), ((T-1), (T-1))) #Demeaning matrix\n",
    "yw_exo = lm.perm(Q_T, y_exo)\n",
    "xw_exo = lm.perm(Q_T, x_exo)\n",
    "\n",
    "# Estimate model\n",
    "exo_test = lm.estimate(yw_exo, xw_exo, T=T-1, transform='fe', robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo = label_x + ['Capital lead']\n",
    "lm.print_table((label_y, label_exo), exo_test, title='Exogeneity FE test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"employment lead\" is significantly different from 0 meaning that we can reject strict exogeniety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead capital and employment\n",
    "F_T = np.eye(T, k=1)[:-1]\n",
    "empl_lead = lm.perm(F_T, x[:, 0].reshape(-1, 1))\n",
    "cap_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))\n",
    "\n",
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)[:-1]\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)\n",
    "\n",
    "# Add empl_lead to x_exo\n",
    "x_exo = np.hstack((x_exo, empl_lead, cap_lead))\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = np.eye(T-1) - np.tile(1/(T-1), ((T-1), (T-1))) #Demeaning matrix\n",
    "yw_exo = lm.perm(Q_T, y_exo)\n",
    "xw_exo = lm.perm(Q_T, x_exo)\n",
    "\n",
    "# Estimate model\n",
    "exo_test = lm.estimate(yw_exo, xw_exo, T=T-1, transform='fe', robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo = label_x + ['Employment lead'] + ['Capital lead']\n",
    "lm.print_table((label_y, label_exo), exo_test, title='Exogeneity FE test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing FD.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_delta = x_diff[:,0].reshape(-1,1)\n",
    "k_delta = x_diff[:,1].reshape(-1,1)\n",
    "l_level = l\n",
    "\n",
    "# Align dimensions over time\n",
    "l_level = np.delete(l_level, np.arange(0, l_level.shape[0], T)).reshape(-1,1)\n",
    "\n",
    "# Stacking in X_delta\n",
    "x_delta = np.column_stack((l_delta, k_delta, l_level))\n",
    "\n",
    "# Estimate the regression by OLS\n",
    "exo_fd = lm.estimate(y=y_diff, x=x_delta, transform='', T=T-1, robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exofd = label_x + ['Employment level']\n",
    "lm.print_table((label_y, label_exofd), exo_fd, title='Exogeneity FD test', floatfmt='.4f')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"employment level\" is not significantly different from 0 meaning that we cannot reject strict exogeniety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_delta = x_diff[:,0].reshape(-1,1)\n",
    "k_delta = x_diff[:,1].reshape(-1,1)\n",
    "k_level = k\n",
    "\n",
    "# Align dimensions over time\n",
    "k_level = np.delete(k_level, np.arange(0, k_level.shape[0], T)).reshape(-1,1)\n",
    "\n",
    "# Stacking in X_delta\n",
    "x_delta = np.column_stack((l_delta, k_delta, k_level))\n",
    "\n",
    "# Estimate the regression by OLS\n",
    "exo_fd = lm.estimate(y=y_diff, x=x_delta, transform='', T=T-1, robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exofd = label_x + ['Capital level']\n",
    "lm.print_table((label_y, label_exofd), exo_fd, title='Exogeneity FD test', floatfmt='.4f')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"capital level\" is not significantly different from 0 meaning that we cannot reject strict exogeniety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_delta = x_diff[:,0].reshape(-1,1)\n",
    "k_delta = x_diff[:,1].reshape(-1,1)\n",
    "k_level = k\n",
    "l_level = l\n",
    "\n",
    "# Align dimensions over time\n",
    "l_level = np.delete(l_level, np.arange(0, l_level.shape[0], T)).reshape(-1,1)\n",
    "k_level = np.delete(k_level, np.arange(0, k_level.shape[0], T)).reshape(-1,1)\n",
    "\n",
    "# Stacking in X_delta\n",
    "x_delta = np.column_stack((l_delta, k_delta, l_level, k_level))\n",
    "\n",
    "# Estimate the regression by OLS\n",
    "exo_fd = lm.estimate(y=y_diff, x=x_delta, transform='', T=T-1, robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exofd = label_x + ['Employment level'] + ['Capital level']\n",
    "lm.print_table((label_y, label_exofd), exo_fd, title='Exogeneity FD test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Residual Sum of Squares (RSS)\n",
    "RSS_fd=fd_result['SSR'] \n",
    "RSS_fdlevel=exo_fd['SSR']\n",
    "\n",
    "# Number of restrictions (q) - here we are testing 2 restrictions (k_lag and l_lag)\n",
    "q = 2\n",
    "\n",
    "# Number of observations (n) and parameters in the augmented model (p_aug)\n",
    "n = len(dat)\n",
    "x_delta = np.column_stack((l_delta, k_delta, l_level,k_level))\n",
    "x_delta = x_delta.shape[1]  # Number of parameters in the augmented model\n",
    "\n",
    "# Compute the F-statistic\n",
    "F_stat = ((RSS_fd - RSS_fdlevel) / q) / (RSS_fdlevel / (n - x_delta - 1))\n",
    "\n",
    "from scipy import stats\n",
    "p_value = 1 - stats.f.cdf(F_stat, q, n - x_delta)\n",
    "\n",
    "print(f\"F-statistic: {F_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef42839c56fd8bee084dafb278faf4416bb17c87278e59e0e4bb5f7c8f27c505"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
