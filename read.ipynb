{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Technology\n",
    "\n",
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import Project_1 as lm\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import f\n",
    "from numpy import linalg as la\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('firms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['lcap','lemp','ldsa']].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='lemp', y='ldsa', data=dat); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data to numpy format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.ldsa.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = dat.firmid.unique().size\n",
    "T = dat.year.unique().size\n",
    "assert dat.shape[0] == N*T, f'Error: data is not a balanced panel'\n",
    "print(f'Data has N={N} and T={T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from `pandas` to `numpy` arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dat.ldsa.values.reshape((N*T,1))\n",
    "\n",
    "ones = np.ones((N*T,1))\n",
    "l = dat.lemp.values.reshape((N*T,1))\n",
    "k = dat.lcap.values.reshape((N*T,1))\n",
    "x = np.hstack([l, k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for odd years\n",
    "dat_odd_years = dat[dat['year'] % 2 != 0].copy()\n",
    "\n",
    "# Update T\n",
    "T = dat_odd_years.year.unique().size\n",
    "assert dat_odd_years.shape[0] == N*T, f'Error: data is not a balanced panel'\n",
    "print(f'Data has N={N} and T={T}')\n",
    "\n",
    "#naming the dependent and independent variables\n",
    "label_y = 'Log deflated sales'\n",
    "label_x = [\n",
    "    'log of employment',\n",
    "    'log of adjusted capital stock'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "Q_T = np.eye(T) - np.tile(1/T, (T, T))\n",
    "y_dot = lm.perm(Q_T, y)\n",
    "x_dot = lm.perm(Q_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_dot, label_x_dot = lm.remove_zero_columns(x_dot, label_x)\n",
    "\n",
    "# Estimate \n",
    "fe_result = lm.estimate(y_dot, x_dot, transform='fe', T=T, robust_se='True')\n",
    "lm.print_table((label_y, label_x_dot), fe_result, title=\"Fixed Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "D_T = (np.eye(T) - np.eye(T, k=-1))[1:]\n",
    "\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_diff, label_x_diff = lm.remove_zero_columns(x_diff, label_x)\n",
    "\n",
    "# Estimate \n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', T=T-1, robust_se='True')\n",
    "lm.print_table((label_y, label_x_diff), fd_result, title=\"First Difference\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for strict exogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To lead variables\n",
    "F_T = np.eye(T, k=1)[:-1]\n",
    "\n",
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)[:-1]\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = np.eye(T-1) - np.tile(1/(T-1), ((T-1), (T-1))) #Demeaning matrix\n",
    "yw_exo = lm.perm(Q_T, y_exo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing FE.1 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead employment\n",
    "empl_lead = lm.perm(F_T, x[:, 0].reshape(-1, 1))\n",
    "\n",
    "# Add empl_lead to x_exo\n",
    "x_exo_empl = np.hstack((x_exo, empl_lead))\n",
    "\n",
    "# Within transform the data\n",
    "xw_exo_empl = lm.perm(Q_T, x_exo_empl)\n",
    "\n",
    "# Estimate model\n",
    "exo_test_empl = lm.estimate(yw_exo, xw_exo_empl, T=T-1, transform='fe', robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo_empl = label_x + ['Employment lead']\n",
    "lm.print_table((label_y, label_exo_empl), exo_test_empl, title='Exogeneity FE test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead capital\n",
    "cap_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))\n",
    "\n",
    "# Add cap_lead to x_exo\n",
    "x_exo_cap = np.hstack((x_exo, cap_lead))\n",
    "\n",
    "# Within transform the data\n",
    "xw_exo_cap = lm.perm(Q_T, x_exo_cap)\n",
    "\n",
    "# Estimate model\n",
    "exo_test_cap = lm.estimate(yw_exo, xw_exo_cap, T=T-1, transform='fe', robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo_cap = label_x + ['Capital lead']\n",
    "lm.print_table((label_y, label_exo_cap), exo_test_cap, title='Exogeneity FE test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"employment lead\" is significantly different from 0 meaning that we can reject strict exogeniety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add both leads to x_exo\n",
    "x_exo_joint = np.hstack((x_exo, empl_lead, cap_lead))\n",
    "\n",
    "# Within transform the data\n",
    "xw_exo_joint = lm.perm(Q_T, x_exo_joint)\n",
    "\n",
    "# Estimate model\n",
    "exo_test_joint = lm.estimate(yw_exo, xw_exo_joint, T=T-1, transform='fe', robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo_joint = label_x + ['Employment lead'] + ['Capital lead']\n",
    "lm.print_table((label_y, label_exo_joint), exo_test_joint, title='Exogeneity FE test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of squared residuals \n",
    "RSS_fe = fe_result['SSR'] \n",
    "RSS_felead = exo_test_joint['SSR']\n",
    "\n",
    "# Number of restrictions\n",
    "q = 2\n",
    "\n",
    "# Number of parameters in unrestricted model\n",
    "par = xw_exo_joint.shape[1]\n",
    "\n",
    "#Degrees of freedom in the unrestricted model\n",
    "#df = N*(T-1) - N - par\n",
    "df = N - par - 1\n",
    "              \n",
    "# Compute the F-statistic\n",
    "F_stat = ((RSS_fe - RSS_felead) / q) / (RSS_felead / df)\n",
    "crit_val = f.ppf(0.95, q, df)\n",
    "p_value = 1 - f.cdf(F_stat.item(), q, df)\n",
    "\n",
    "print(f\"F-statistic: {F_stat}\")\n",
    "print(f\"Critical value: {crit_val}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing FD.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define new variables\n",
    "l_delta = x_diff[:,0].reshape(-1,1)\n",
    "k_delta = x_diff[:,1].reshape(-1,1)\n",
    "l_level = l\n",
    "k_level = k\n",
    "\n",
    "# Align dimensions over time\n",
    "l_level = np.delete(l_level, np.arange(0, l_level.shape[0], T)).reshape(-1,1)\n",
    "k_level = np.delete(k_level, np.arange(0, k_level.shape[0], T)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking in X_delta\n",
    "x_delta_l = np.column_stack((l_delta, k_delta, l_level))\n",
    "\n",
    "# Estimate the regression by OLS\n",
    "exo_l = lm.estimate(y=y_diff, x=x_delta_l, transform='', T=T-1, robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo_l = label_x + ['Employment level']\n",
    "lm.print_table((label_y, label_exo_l), exo_l, title='Exogeneity FD test', floatfmt='.4f')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"employment level\" is not significantly different from 0 meaning that we cannot reject strict exogeniety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking in X_delta\n",
    "x_delta_k = np.column_stack((l_delta, k_delta, k_level))\n",
    "\n",
    "# Estimate the regression by OLS\n",
    "exo_k = lm.estimate(y=y_diff, x=x_delta_k, transform='', T=T-1, robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo_k = label_x + ['Capital level']\n",
    "lm.print_table((label_y, label_exo_k), exo_k, title='Exogeneity FD test', floatfmt='.4f')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"capital level\" is not significantly different from 0 meaning that we cannot reject strict exogeniety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking in X_delta\n",
    "x_delta_joint = np.column_stack((l_delta, k_delta, l_level, k_level))\n",
    "\n",
    "# Estimate the regression by OLS\n",
    "exo_joint_fd = lm.estimate(y=y_diff, x=x_delta_joint, transform='', T=T-1, robust_se='True')\n",
    "\n",
    "# Print results\n",
    "label_exo_joint_fd = label_x + ['Employment level'] + ['Capital level']\n",
    "lm.print_table((label_y, label_exo_joint_fd), exo_joint_fd, title='Exogeneity FD test', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of squared residuals \n",
    "RSS_fd = fd_result['SSR'] \n",
    "RSS_fdlevel = exo_joint_fd['SSR']\n",
    "\n",
    "# Number of restrictions\n",
    "q = 2\n",
    "\n",
    "# Number of parameters in unrestricted model\n",
    "par = x_delta.shape[1]\n",
    "\n",
    "#Degrees of freedom in the unrestricted model\n",
    "#df = N*(T-1) - N - par\n",
    "df = N - par - 1\n",
    "              \n",
    "# Compute the F-statistic\n",
    "F_stat = ((RSS_fd - RSS_fdlevel) / q) / (RSS_fdlevel / df)\n",
    "crit_val = f.ppf(0.95, q, df)\n",
    "p_value = 1 - f.cdf(F_stat.item(), q, df)\n",
    "\n",
    "print(f\"F-statistic: {F_stat}\")\n",
    "print(f\"Critical value: {crit_val}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for constant returns to scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define null hypothesis: R * b_hat = 1 (sum of first two coefficients equals 1)\n",
    "R = np.array([[1, 1]])\n",
    "r = np.array([[1]])\n",
    "\n",
    "# Extract b_hat and covariance matrix\n",
    "b_hat = fd_result['b_hat']  # Estimated coefficients\n",
    "cov = fd_result['cov']      # Covariance matrix of coefficients\n",
    "\n",
    "# Perform Wald test\n",
    "w_stat, crit_val, p_value = lm.wald_test(b_hat, cov, R, r)\n",
    "\n",
    "print(f'The test statistic is {w_stat.item():.2f}.')\n",
    "print(f'The critical value at a 5% significance level is {crit_val:.2f}.')\n",
    "print(f'The p-value is {p_value:.8f}.')\n",
    "\n",
    "if w_stat > crit_val:\n",
    "    print(f\"Reject null hypothesis: We reject CRS for the FD-estimation - P-value of: {p_value:.4f}.\")\n",
    "else:\n",
    "    print(f\"Fail to reject null hypothesis: We cannot reject CRS for the FD-estimation. P-value of: {p_value:.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef42839c56fd8bee084dafb278faf4416bb17c87278e59e0e4bb5f7c8f27c505"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
